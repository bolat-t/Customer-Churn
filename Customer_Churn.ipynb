{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - Portfolio Project\n",
    "\n",
    "This notebook uses the **Telco Customer Churn dataset** from Kaggle to demonstrate an end-to-end machine learning pipeline for predicting customer churn.\n",
    "\n",
    "**Portfolio Flow:**\n",
    "1. Intro / Problem Statement\n",
    "2. Dataset Overview (table + stats)\n",
    "3. EDA Visuals (plots)\n",
    "4. Feature Engineering Summary\n",
    "5. Model Comparison Table\n",
    "6. Best Model Results (confusion matrix, ROC, F1)\n",
    "7. Feature Importance Plot\n",
    "8. Business Insights & Recommendations\n",
    "9. Optional Interactive Demo (Streamlit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro / Problem Statement\n",
    "\n",
    "**Problem:** Predict which customers are likely to churn (cancel service) in a telecommunications company.\n",
    "\n",
    "**Goal:** Build a machine learning pipeline to proactively identify high-risk customers and recommend retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "We use the Telco Customer Churn dataset downloaded via KaggleHub. This dataset contains demographic, account, service, and usage information for ~7,000 customers." 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download('blastchar/telco-customer-churn')\n",
    "print('Path to dataset files:', path)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(f'{path}/Telco-Customer-Churn.csv')\n",
    "df.head()" 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert TotalCharges to numeric\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "# Dataset info\n",
    "df.info()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Visualize churn distribution and key feature relationships." 
   ]
  },
 {
"cells": [
{
"cell_type": "code",
"metadata": {},
"source": [
"import matplotlib.pyplot as plt\n",
"import seaborn as sns\n",
"\n",
"# Churn distribution\n",
"plt.figure(figsize=(6,4))\n",
"sns.countplot(data=df, x='Churn')\n",
"plt.title('Churn Distribution')\n",
"plt.show()\n",
"\n",
"# Churn rate by Contract type\n",
"plt.figure(figsize=(8,4))\n",
"sns.barplot(x='Contract', y='Churn', data=df, estimator=lambda x: x.mean())\n",
"plt.ylabel('Churn Rate')\n",
"plt.title('Churn Rate by Contract Type')\n",
"plt.show()\n",
"\n",
"# Churn rate by Internet Service\n",
"plt.figure(figsize=(8,4))\n",
"sns.barplot(x='InternetService', y='Churn', data=df, estimator=lambda x: x.mean())\n",
"plt.ylabel('Churn Rate')\n",
"plt.title('Churn Rate by Internet Service')\n",
"plt.show()"
]
}
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "- Encode Yes/No columns\n",
    "- Create tenure categories\n",
    "- Identify if customer has internet services" 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Encode Yes/No columns\n",
    "yes_no_cols = ['Partner','Dependents','PhoneService','PaperlessBilling','Churn',\n",
    "               'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n",
    "for col in yes_no_cols:\n",
    "    df[col] = df[col].map({'Yes':1,'No':0})\n",
    "\n",
    "# Tenure categories\n",
    "df['tenure_category'] = pd.cut(df['tenure'], bins=[0,12,24,48,72], labels=['0-12','12-24','24-48','48-72'])\n",
    "\n",
    "# Has internet service\n",
    "df['has_internet'] = df['InternetService'].apply(lambda x: 0 if x=='No' else 1)\n",
    "\n",
    "df.head()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training & Comparison\n",
    "\n",
    "Train Logistic Regression, Random Forest, Gradient Boosting and compare metrics." 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(['customerID','Churn'], axis=1).select_dtypes(include=['int64','float64'])\n",
    "y = df['Churn']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "    results[name] = {'model':model,'y_pred':y_pred,'y_proba':y_proba,'roc_auc':roc_auc_score(y_test,y_proba),'f1_score':f1_score(y_test,y_pred),'accuracy':model.score(X_test_scaled,y_test)}\n",
    "\n",
    "results_df = pd.DataFrame([{**{'Model':k}, **v} for k,v in results.items()])[['Model','accuracy','roc_auc','f1_score']]\n",
    "results_df" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Model Results & Metrics\n",
    "\n",
    "Confusion matrix, classification report, and ROC for the best performing model." 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "best_model_name = results_df.sort_values('roc_auc', ascending=False)['Model'].iloc[0]\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "y_proba_best = results[best_model_name]['y_proba']\n",
    "\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Retained','Churned']))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best, display_labels=['Retained','Churned'], cmap='Blues')\n",
    "plt.show()\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba_best)\n",
    "plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "\n",
    "Display the top features influencing churn prediction." 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_importance = pd.DataFrame({'Feature':X.columns, 'Importance':best_model.coef_[0] if best_model_name=='Logistic Regression' else best_model.feature_importances_})\n",
    "feature_importance['Importance'] = feature_importance['Importance'].abs()\n",
    "feature_importance.sort_values('Importance', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Insights & Recommendations\n",
    "\n",
    "Identify high-risk customers and calculate potential retention impact." 
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "high_risk_threshold = 0.7\n",
    "high_risk_customers = (y_proba_best>=high_risk_threshold).sum()\n",
    "avg_customer_value = df['TotalCharges'].mean()\n",
    "retention_rate = 0.25\n",
    "retention_cost_per_customer = 50\n",
    "potential_saves = high_risk_customers*retention_rate*avg_customer_value\n",
    "intervention_cost = high_risk_customers*retention_cost_per_customer\n",
    "net_benefit = potential_saves - intervention_cost\n",
    "\n",
    "print(f'High-Risk Customers: {high_risk_customers}')\n",
    "print(f'Potential Saves: ${potential_saves:,.2f}')\n",
    "print(f'Net Benefit: ${net_benefit:,.2f}')" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional Interactive Demo\n",
    "\n",
    "This notebook can be converted into a **Streamlit app** for live predictions and interactive visualizations.\n",
    "Example: `streamlit run telco_churn_app.py`" 
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3","language": "python","name": "python3"},"language_info": {"name": "python","version": "3.11"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
